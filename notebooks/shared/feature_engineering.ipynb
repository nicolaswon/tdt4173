{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/nwong/Workspace/Projects/tdt4173_project/src\")\n",
    "\n",
    "from feature_engineering.bus_stop_features import *\n",
    "from feature_engineering.demographic_features import *\n",
    "from feature_engineering.demographic_features import *\n",
    "from feature_engineering.store_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "bus_stops_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/busstops_norway.csv\")\n",
    "grunnkrets_age_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/grunnkrets_age_distribution.csv\")\n",
    "grunnkrets_household_pop_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/grunnkrets_households_num_persons.csv\")\n",
    "grunnkrets_household_inc_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/grunnkrets_income_households.csv\")\n",
    "grunnkrets_norway_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/grunnkrets_norway_stripped.csv\")\n",
    "plaace_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/plaace_hierarchy.csv\")\n",
    "stores_extra_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/stores_extra.csv\")\n",
    "stores_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/stores_train.csv\")\n",
    "stores_test_df = pd.read_csv(\"/Users/nwong/Workspace/Projects/tdt4173_project/data/raw/stores_test.csv\")\n",
    "\n",
    "stores_df = stores_df[stores_df['year'] == 2016].merge(plaace_df, on=\"plaace_hierarchy_id\", how=\"left\")\n",
    "stores_extra_df = stores_extra_df[stores_extra_df['year'] == 2016]\n",
    "\n",
    "# grunnkrets_norway_df = grunnkrets_norway_df[grunnkrets_norway_df['year'] == 2016]\n",
    "# bus_stops_df = bus_stops_lat_lon(bus_stops_df)\n",
    "\n",
    "# merged_df = stores_df.merge(grunnkrets_norway_df, how=\"left\", on=\"grunnkrets_id\").merge(plaace_df, how=\"left\", on=\"plaace_hierarchy_id\")\n",
    "\n",
    "# geo_groups = ['grunnkrets_name','district_name','municipality_name']\n",
    "\n",
    "# store_types = ['lv1_desc', 'lv2_desc', 'lv3_desc', 'lv4_desc']\n",
    "\n",
    "# stop_importance_levels = list(bus_stops_df['importance_level'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = stores_df.merge(plaace_df, on=\"plaace_hierarchy_id\", how=\"left\")\n",
    "stores_in_radius(stores_df, stores_df, radius=0.1, store_type_group='lv1_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_per_store_type = population_per_store_type_grouped_by_geo_groups(stores_test_df, plaace_df, grunnkrets_norway_df, grunnkrets_age_df, geo_groups=geo_groups, store_types=store_types, agg_string=\"pop_per_num_stores\")\n",
    "# pop_density = population_density_grouped_by_geo_group(stores_test_df, grunnkrets_age_df, grunnkrets_norway_df)\n",
    "# pop_count_df = population_count_grouped_by_geo_group(stores_test_df, grunnkrets_age_df, grunnkrets_norway_df, geo_groups=geo_groups)\n",
    "# age_dist_df = age_dist_by_geo_group(stores_test_df, grunnkrets_age_df, grunnkrets_norway_df)\n",
    "# house_hold_dist = household_dist_by_geo_group(stores_test_df, grunnkrets_household_pop_df, grunnkrets_norway_df)\n",
    "\n",
    "# is_mall_df = is_mall_only(stores_test_df)\n",
    "# is_chain_df = is_chain_only(stores_test_df)\n",
    "# store_types_count = store_types_all_count_by_geo_groups(stores_test_df, plaace_df, grunnkrets_norway_df, store_types=store_types, geo_groups=geo_groups)\n",
    "# store_types_revenue = store_types_all_revenue_by_geo_groups(stores_df, stores_test_df, plaace_df, grunnkrets_norway_df, store_types=store_types, geo_groups=geo_groups)\n",
    "# store_radius = stores_in_radius_by_type(stores_test_df, plaace_df, store_types=store_types, radius = 0.1)\n",
    "\n",
    "# busstop_distance = bus_stops_distance_by_importance(stores_test_df, bus_stops_df, stop_importance_levels = stop_importance_levels)\n",
    "# busstop_radius = bus_stops_in_radius_by_importance(stores_test_df, bus_stops_df, stop_importance_levels=stop_importance_levels, radius = 0.1)\n",
    "\n",
    "# df = (pop_count_df.merge(age_dist_df, how = \"left\", on = \"store_id\")\n",
    "#     .merge(house_hold_dist, how = \"left\", on =\"store_id\")\n",
    "#     .merge(pop_per_store_type, how = \"left\", on = \"store_id\")\n",
    "#     .merge(pop_density, how = \"left\", on  = \"store_id\")\n",
    "#     .merge(is_mall_df, how = \"left\", on = \"store_id\")\n",
    "#     .merge(is_chain_df, how = \"left\", on = \"store_id\")\n",
    "#     #.merge(income_df, how = \"left\", on = \"store_id\")\n",
    "#     .merge(store_types_count, how =\"left\", on = \"store_id\")\n",
    "#     .merge(store_types_revenue, how = \"left\", on = \"store_id\")\n",
    "#     #.merge(id_and_revenue_df, how = \"left\", on = \"store_id\")\n",
    "#     .merge(store_radius, how = \"left\", on = \"store_id\")\n",
    "#     .merge(busstop_distance,how = \"left\", on = \"store_id\")\n",
    "#     .merge(busstop_radius, how =\"left\", on =\"store_id\" )\n",
    "# )\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = stores_df.drop(\"revenue\", axis=1)\n",
    "stores_labels = stores_df['revenue'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "stores_num = stores.select_dtypes(include=[np.number])\n",
    "X = imputer.fit_transform(stores_num)\n",
    "stores_tr = pd.DataFrame(X, columns=stores_num.columns, index=stores_num.index)\n",
    "stores_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "stores_cat = stores[['chain_name']]\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "stores_cat_lhot = cat_encoder.fit_transform(stores_cat)\n",
    "pd.DataFrame(stores_cat_lhot.toarray(), columns=cat_encoder.get_feature_names_out(), index=stores_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform feature with a heavy tail prior to scaling. Otherwise, the values will get squashed by outliers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "cat_attribs = [\"sales_channel_name\", \"chain_name\", \"mall_name\"]\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    # SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    ")\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])\n",
    "\n",
    "stores_preped = preprocessing.fit_transform(stores[cat_attribs])\n",
    "pd.DataFrame(stores_preped, columns=preprocessing.get_feature_names_out(), index=stores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "stores_num_std_scaled = std_scaler.fit_transform(stores_num)\n",
    "pd.DataFrame(stores_num_std_scaled, columns=stores_num.columns, index=stores_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "ratio_transformer = FunctionTransformer(lambda X: X[:, [0]] / X[:, [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.kmeans_ = KMeans(self.n_clusters, random_state=self.random_state)\n",
    "        self.kmeans_.fit(X, sample_weight=sample_weight)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n",
    "    \n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return [f'Cluster {i} similarity' for i in range(self.n_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "cluster_simil = ClusterSimilarity(n_clusters=15, gamma=1.,random_state=42)\n",
    "cluster_simil.fit_transform(stores[['lat', 'lon']], sample_weight=stores_labels)\n",
    "print(pd.DataFrame(cluster_simil.kmeans_.cluster_centers_))\n",
    "plt.scatter(pd.DataFrame(cluster_simil.kmeans_.cluster_centers_)[1], pd.DataFrame(cluster_simil.kmeans_.cluster_centers_)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = store_types_all_count_by_geo_groups(stores_df, plaace_df, grunnkrets_norway_df, store_types, geo_groups)\n",
    "population = population_grouped_by_geo_group(stores_df, grunnkrets_age_df, grunnkrets_norway_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_density_all_by_geo_groups(stores_df, population_df):\n",
    "    merged_df = pd.concat([stores_df, population_df], axis=1)\n",
    "    print(merged_df)\n",
    "    merged_df[['a', 'b', 'c', 'd']] = merged_df[['grunnkrets_name_lv1_desc','grunnkrets_name_lv2_desc', 'grunnkrets_name_lv3_desc', 'grunnkrets_name_lv4_desc']] / merged_df['grunnkrets_name_population_count'].to_numpy()\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_density_all_by_geo_groups(stores, population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_per_store_types(stores_df, plaace_hierarchy, grunnkrets_df, age_df, agg_name, geo_group, store_type_group): \n",
    "    grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]\n",
    "    num_stores_types_by_geo_group = store_types_count_by_geo_group(stores_df, plaace_hierarchy, grunnkrets_df_2016, agg_name, geo_group, store_type_group)\n",
    "    pop_grouped_by_geo = population_grouped(age_df, grunnkrets_df_2016, geo_group)\n",
    "    combined_df = num_stores_types_by_geo_group.merge(pop_grouped_by_geo, how = \"left\", on = geo_group)\n",
    "    combined_df[\"population_per_num_store\"] = combined_df[\"population_count\"] / combined_df[agg_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_per_store_types(stores_df, plaace_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops_distance_by_importance(stores_df, bus_stops_df, stop_importance_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops_in_radius_by_importance(stores_df, bus_stops_df, stop_importance_levels, radius=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_in_radius_by_type(stores_df, plaace_df, store_types, radius=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_types_all_count_by_geo_groups(stores_df, plaace_df, grunnkrets_norway_df, store_types, geo_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_types_all_revenue_by_geo_groups(stores_df, plaace_df, grunnkrets_norway_df, store_types, geo_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tdt4173')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bdd567d542e0573c37c1678690b38e6dc69362d1ffcf1745cf7590ba4a94573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
